# Install necessary packages
!pip install diffusers["torch"] transformers
!pip install accelerate
!pip install git+https://github.com/huggingface/diffusers

# Import required libraries
import torch
from diffusers import StableDiffusionPipeline
from IPython.display import display

# Load the diffusion model pipeline
pipe = StableDiffusionPipeline.from_pretrained("digiplay/majicMIX_realistic_v6", torch_dtype=torch.float16)

# Move the model pipeline to GPU if available
pipe = pipe.to("cuda")

# Disable safety checker to speed up inference
pipe.safety_checker = None

# Define the prompt for generating images
prompt = "most beautiful indian girl in forest background, artgerm, artstation, octane render, elegant, model, gorgeous, vray, depth of field, 8 k, by karol bak, donato giancola, 3 d, trending on artstation, octane render, cinematic lighting, hyper realism, high detail, octane render, 8 k"

# Set height and width for generated images
h = 800
w = 480

# Number of diffusion steps
steps = 30

# Guiding scale for the diffusion process
guidance = 7.5

# Negative prompt for image generation
neg = "BadDream, FastNegativeV2"

# Number of images to generate
num_images = 5

# Generate and display the images
images = []
for _ in range(num_images):
    # Generate image using diffusion model pipeline
    image = pipe(prompt, height=h, width=w, num_inference_steps=steps, guidance_scale=guidance, negative_prompt=neg).images[0]
    images.append(image)

# Display generated images
for img in images:
    display(img)
